#!/bin/bash
# @configure_input@
#============================================================================
#
#     This file is part of the Code_Saturne Kernel, element of the
#     Code_Saturne CFD tool.
#
#     Copyright (C) 1998-2009 EDF S.A., France
#
#     contact: saturne-support@edf.fr
#
#     The Code_Saturne Kernel is free software; you can redistribute it
#     and/or modify it under the terms of the GNU General Public License
#     as published by the Free Software Foundation; either version 2 of
#     the License, or (at your option) any later version.
#
#     The Code_Saturne Kernel is distributed in the hope that it will be
#     useful, but WITHOUT ANY WARRANTY; without even the implied warranty
#     of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with the Code_Saturne Kernel; if not, write to the
#     Free Software Foundation, Inc.,
#     51 Franklin St, Fifth Floor,
#     Boston, MA  02110-1301  USA
#
#============================================================================
#
########################################################################
#
#                  BATCH FILE FOR THE CCRT (Platine under LSF)
#                  ===========================================
#
#BSUB -n 2
#BSUB -W 00:05
#BSUB -o nameandcaseo.%J
#BSUB -e nameandcasee.%J
#BSUB -J nameandcase
#
#  -n : number of processors
#  -W : walltime as hh:mm
#  -o : output file name
#  -e : error file name
#  -J : job name
#
# ------------------------------------------------------------------
#
#                  BATCH FILE FOR THE Chatou CLUSTER (PBS)
#                  =======================================
#
#PBS -l nodes=4:ppn=2
#PBS -l walltime=1:00:00
#PBS -l mem=320mb
#
#PBS -j eo
#PBS -N nameandcase
#
#  nodes    : number of nodes
#  ppn      : number of process per node
#  walltime : wall clock time (hh:mm:ss)
#  mem      : memory
#
#WARNING: when coupling with SYRTHES, 1 processor will be reserved for each
#         instance of SYRTHES. The Kernel will be executed on the remaining
#         processors, so make sure to reserve a sufficiently high number
#         of processors.
#
# ------------------------------------------------------------------
#
#                  BATCH FILE (University of Manchester Cluster)
#                  =============================================
#
# set the name of the job
##$ -N nameandcase
#
# request between 2 and 4 slots
##$ -pe mpich 2-4
#
# Execute the job from the current working directory
# Job output will appear in this directory
##$ -cwd
#   can use -o dirname to redirect stdout
#   can use -e dirname to redirect stderr

#  Export these environment variables
##$ -v MPI_HOME

#set -x
#
# ------------------------------------------------------------------
#
#                  BATCH FILE (AIX, Loadlever)
#                  ===========================
#
#@ shell = /bin/sh
#
#@ job_name = nameandcase
#
#@ job_type = parallel
#@ cpus = 128
#@ node_usage = not_shared
#
#@ network.MPI = csss,shared,US
#@ bulkxfer = yes
#
#@ wall_clock_limit = 00:20:00
#@ account_no = z001
#
#@ output = $(job_name).$(schedd_host).$(jobid).out
#@ error  = $(job_name).$(schedd_host).$(jobid).err
#@ notification = never
#
#@ queue
# suggested environment settings:
#  export MP_EAGER_LIMIT=65536
#  export MP_SHARED_MEMORY=yes
#  export MEMORY_AFFINITY=MCM
#  export MP_TASK_AFFINITY=MCM
#
########################################################################
#
# BEGINNING OF USER MODIFIABLE ZONE FOR STANDARD CALCULATIONS
#
# runcase.help gives more details about the different variables.
#
#                    -------------------------------
#
NB_INSTANCES=2
#
# On some systems, some external libraries may require TERM to be defined.
export TERM=xterm
#
STUDY=STUDYNAME
CASE=CASENAME
#
# Parameters for the 1st instance 
# -------------------------------
PARAM_1=
MESH_1=
COMMAND_REORIENT_1=
COMMAND_JOIN_1=
COMMAND_CWF_1=
COMMAND_PERIO_1=
THERMOCHEMISTRY_DATA_1=
METEO_DATA_1=
#
# Choose the total number of processors used (if empty, automatic detection
# through the batch system if possible, set to 1 otherwise).
# When coupling with SYRTHES with COUPLING_MODE=MPI, the 1st processor is
# used by SYRTHES, so the effective number of processors assigned to the
# Kernel is reduced by 1.
# The processors list is only usable when not running on a batch system
# (as such a system usually already defines a similar list)
NUMBER_OF_PROCESSORS_1=1
PROCESSOR_LIST_1=
#
PARTITION_LIST_1=
#
USER_INPUT_FILES_1=""
USER_OUTPUT_FILES_1=""
#
# Parameters for the 2nd instance 
# -------------------------------
PARAM_2=
MESH_2=
COMMAND_REORIENT_2=
COMMAND_JOIN_2=
COMMAND_CWF_2=
COMMAND_PERIO_2=
THERMOCHEMISTRY_DATA_2=
METEO_DATA_2=
#
# Choose the total number of processors used (if empty, automatic detection
# through the batch system if possible, set to 1 otherwise).
# When coupling with SYRTHES with COUPLING_MODE=MPI, the 1st processor is
# used by SYRTHES, so the effective number of processors assigned to the
# Kernel is reduced by 1.
# The processors list is only usable when not running on a batch system
# (as such a system usually already defines a similar list)
NUMBER_OF_PROCESSORS_2=1
PROCESSOR_LIST_2=
#
PARTITION_LIST_2=
#
USER_INPUT_FILES_2=""
USER_OUTPUT_FILES_2=""
#
# Global parameters
# -----------------
# Working directory (leave empty for automatic default directory)
CS_TMP_PREFIX=
#CS_TMP_PREFIX=/local00/users/`whoami`
#
CS_LIB_ADD=
VALGRIND=
#
ARG_CS_VERIF=""
ARG_CS_OUTPUT=""
ECHOCOMM=""
#
summary=summary
CASEDIR=CASEDIRNAME
#DATA=$CASEDIR/DATA
RESU=$CASEDIR/RESU
#SRC=$CASEDIR/SRC
SCRIPTS=$CASEDIR/SCRIPTS
#RESTART_IN=$DATA/RESTART
#PREPROCESSOR_OUTPUT_IN=$DATA/preprocessor_output
#PARTITION_OUTPUT_IN=$DATA/PARTITION_OUTPUT
MESHDIR=$CASEDIR/../MESH
#
#  Indicate which steps should be executed; if both the Preprocessor and the
#  Kernel are executed, the "preprocessor_output" and eventual "domain_number_*"
#  files are not saved. If only the preprocessor and / or partitioner are
#  executed, the corresponding files will be saved in a RESU/PREPROCESSOR_OUTPUT
#  and RESU/PARTITION directory. If the Preprocessor is not executed,
#  "preprocessor_output" will be read from $PREPROCESSOR_OUTPUT_IN. If the
#  Partitioner is not executed, "domain_number_*" will be read from
#  $PARTITION_OUTPUT_IN if available (otherwise, unoptimized default
#  partitioning will be used).
#
#  EXEC_PREPROCESS : should the Preprocessor be run ? (yes/no)
#  EXEC_PARTITION  : should the Partitioner be run ? (yes/no)
#  EXEC_KERNEL     : should the Kernel be run ? (yes/no)
#
EXEC_PREPROCESS=yes
EXEC_PARTITION=yes
EXEC_KERNEL=yes
#
#
#
########################################################################
#
# END OF USER MODIFIABLE ZONE FOR STANDARD CALCULATIONS
#
########################################################################
#
# Kernel installation parameters
#
prefix=@prefix@
#
exec_prefix=@exec_prefix@
bindir=@bindir@
datarootdir=@datarootdir@
datadir=@datadir@
pkgdatadir=${datadir}/@PACKAGE@
#
# Preprocessor installation parameters
#
ecs_prefix=@ecs_prefix@
#
ecs_exec_prefix=${ecs_prefix}
ecs_bindir=${ecs_exec_prefix}/bin
#
########################################################################
#
# Parameters for execution
#
# General variables
THISSCRIPT=$0
USER=`whoami`
DATE=`date '+%m%d%H%M'`
SUFFIX=$DATE
EXE=cs_solver
#
# Copy runcase before changing to the working directory
# (as after that, the relative path will not be up to date).
#
cp $0 $RESU/runcase.$SUFFIX
#
# Execution directory (reachable by all the processors)
#
if [ ! -z "$CS_TMP_PREFIX" ] ; then
  RUN=${CS_TMP_PREFIX}/tmp_Saturne/$STUDY.$CASE.$DATE
#
else
#  Default if not specified by the user
#
#  On the CCRT, there is no TMPDIR. We work by default in SCRATCHDIR
  if [ "$SCRATCHDIR" != "" ] ; then
    RUN=$SCRATCHDIR/tmp_Saturne/$STUDY.$CASE.$DATE
#
  elif [ "$TMPDIR" != "" -a "$TMPDIR" != "/tmp" ] ; then
    RUN=$TMPDIR/tmp_Saturne/$STUDY.$CASE.$DATE
  else
    RUN=$HOME/tmp_Saturne/$STUDY.$CASE.$DATE
  fi
fi
#
# Create directory if necessary
if [ "$RUN" != "$TMPDIR" ] ; then
  if [ ! -d $RUN ] ; then
    mkdir -p $RUN || exit 1
  else
    echo "RUN=$RUN already exists."
    echo "The simulation will not be run."
    exit 1
  fi
fi
#
cd $RUN
#
# Create a working directory for each instance
I=0
while [ $I -lt $NB_INSTANCES ]; do
  (( I=I+1 ))
  mkdir RUN.$I || exit 1
done
#
########################################################################
#
# Set up MPI environment
#
# Use makefile query to obtain the path to MPI binaries if those are
# not on the default path. This is a peculiar use of make, but allows
# us to avoid defining the MPI configuration in multiple files.

CS_MPI_PATH=@MPI_BIN@

N_PROCS=0
I=0
while [ $I -lt $NB_INSTANCES ]; do
    (( I=I+1 ))
    N_PROCS=`eval echo '$NUMBER_OF_PROCESSORS_'$I`
    (( NUMBER_OF_PROCESSORS=NUMBER_OF_PROCESSORS+$N_PROCS ))
done

# NUMBER_OF_PROCESSORS is determined here if not already set;
# MPIHOSTS, MPIRUN, MPIBOOT, MPIHALT, and NUMBER_OF_NODES are
# defined by the sourced script, and PATH may be updated.
#
. ${pkgdatadir}/runcase_mpi_env
#
echo
echo
#
echo "Coupling of several Code_Saturne executables activated."
#
########################################################################
# Greeting message
#
echo ' '
echo '                      Code_Saturne is running '
echo '                      *********************** '
echo ' '
echo ' Working directory (to be periodically cleaned) : '
echo '    ' $RUN
#
########################################################################
#
# Compilation and link
#
# Note: we also check the for the presence of certain user subroutines here.
#
echo
echo ' Kernel version:          ' $prefix
echo ' Preprocessor version:    ' $ecs_prefix

if [ "${EXEC_KERNEL}" = "yes" ] ; then

I=0
while [ $I -lt $NB_INSTANCES ]; do
  (( I=I+1 ))

  cur_dir=$RUN/RUN.$I
  cd $cur_dir

  PARAM=`eval echo '$PARAM_'$I`
  SRC=$CASEDIR/SRC.$I

  source_cas=$SRC

  #
  # Copy of the parameter file
  if [ ! -z "$PARAM" ] ; then
    var=$DATA/$PARAM
    if [ -f $var ] ; then
      COMMAND_PARAM="--param $PARAM"
      cp $var .
    else
      echo ' '
      echo ' -- ERROR -- '
      echo ' The parameters file ' $var
      echo ' can not be accessed.'
      exit 1
    fi
  fi

  src_files=`ls ${source_cas}/*.[fF]90 ${source_cas}/*.[ch] 2>/dev/null`

  if [ ! -z "${src_files}" ] ; then

if [ $I -eq 1 ]; then
    echo
    echo  "  ***************************************************************"
    echo  "   Compilation of user subroutines and linking of Code_Saturne"
    echo  "  ***************************************************************"
fi

    if [ -f compil.log ] ; then
      rm -f compil.log
    fi

    src_dir="src_saturne"

    # Copy of the user source files
    # (no links: the directory is copied later)
    mkdir ${src_dir}
    for f in ${src_files} ; do
      if [ -f $f ] ; then
        cp ${f} ${src_dir}/
      fi
    done

    # Detect presence and test for compatibility of modules.
    if [ ! -z "$PARAM" ] ; then
      ${bindir}/cs_check_consistency --source=$src_dir --param=$PARAM
    else
      ${bindir}/cs_check_consistency
    fi
    if [ $? = 1 ] ; then
      exit 1
    fi

    # Compilation
    if [ ! -z "${CS_LIB_ADD}" ] ; then
      OPTLIBS="--opt-libs=${CS_LIB_ADD}"
    fi
    ${bindir}/cs_compile \
      --source=$src_dir ${OPTLIBS} 2>>$cur_dir/compil.log 1>&2
    if [ $? -ne 0 ]
    then
      cp $cur_dir/compil.log $RESU/compil.log.$I.$SUFFIX
      echo "COMPILE OR LINK ERROR"
      rm -f *.o
      exit 1
    else
      cp $cur_dir/compil.log $RESU/compil.log.$I.$SUFFIX
    fi

  else

    # Detect presence and test for compatibility of modules.
    if [ ! -z "$PARAM" ] ; then
      ${bindir}/cs_check_consistency --param=$PARAM
    else
      ${bindir}/cs_check_consistency
    fi
    if [ $? = 1 ] ; then
      exit 1
    fi

    ln -s ${bindir}/$EXE .

  fi

done

fi # EXEC_KERNEL = yes

#
########################################################################
#
# Data setup
#
echo
echo  "  ********************************************"
echo  "             Preparing calculation            "
echo  "  ********************************************"
echo
#
ERROR=false
PREPROCESS_ERROR=false
PARTITION_ERROR=false
EXECUTION_ERROR=false
#
I=0
while [ $I -lt $NB_INSTANCES ]; do
#
  (( I=I+1 ))
#
  cur_dir=$RUN/RUN.$I
  cd $cur_dir
#

  MESH=`eval echo '$MESH_'$I`
  COMMAND_JOIN=`eval echo '$COMMAND_JOIN_'$I`
  COMMAND_CWF=`eval echo '$COMMAND_CWF_'$I`
  COMMAND_PERIO=`eval echo '$COMMAND_PERIO_'$I`

  nproc_kernel=`eval echo '$NUMBER_OF_PROCESSORS_'$I`

  SRC=$CASEDIR/SRC.$I
  DATA=$CASEDIR/DATA.$I
  RESTART_IN=$DATA/RESTART_IN
  PREPROCESSOR_OUTPUT_IN=$DATA/preprocessor_output
  PARTITION_OUTPUT_IN=$DATA/PARTITION_OUTPUT
#
if [ "${EXEC_PREPROCESS}" = "yes" ]
then
  for var in $MESH ; do
    ln -s $MESHDIR/$var $var || exit 1
    # Special case for meshes in EnSight format: link to .geo file necessary
    # (retrieve name through .case file)
    var2=`basename $var .case`
    if [ $var2 != $var ] ; then
      ficgeo_ensight=`awk '/^model:/ {print $2}' $var`
      ln -s $MESHDIR/$ficgeo_ensight $ficgeo_ensight || FIN
    fi
  done
else
  if [ -f ${PREPROCESSOR_OUTPUT_IN} ] ; then
    ln -s ${PREPROCESSOR_OUTPUT_IN} preprocessor_output || exit 1
  else
    echo "Error: no preprocessor output file is available;"
    echo "       (${PREPROCESSOR_OUTPUT_IN} does not exist."
    echo "       or is not a standard file."
    exit 1
  fi
fi
#
if [ $nproc_kernel -eq 1 -a "${EXEC_KERNEL}" = "yes" ] ; then
  EXEC_PARTITION=no
elif [ "${EXEC_PARTITION}" = "no" -a "${PARTITION_OUTPUT_IN}" != "" ]
then
  if [ -f ${PARTITION_OUTPUT_IN}/domain_number_${nproc_kernel} ] ; then
    ln -s ${PARTITION_OUTPUT_IN}/domain_number_${nproc_kernel} .
  else
    echo "Warning: no partitioning file is available;"
    echo "         (no ${PARTITION_OUTPUT_IN}/domain_number_${nproc_kernel})."
    echo
    echo "         Unoptimized partitioning will be used."
    echo "         Parallel performance may be degraded."
  fi
fi
#
if [ "${EXEC_KERNEL}" = "yes" ] ; then

  THERMOCHEMISTRY_DATA=`eval echo '$THERMOCHEMISTRY_DATA_'$I`
  METEO_DATA=`eval echo '$METEO_DATA_'$I`
  USER_INPUT_FILES=`eval echo '$USER_INPUT_FILES_'$I`

  for var in ${RESTART_IN}/* ; do
    if [ -f $var ] ; then
      varb=`basename $var`
      if   [ $varb = suiava ] ; then
        vara=suiamo
      elif [ $varb = suiavx ] ; then
        vara=suiamx
      elif [ $varb = vorava ] ; then
        vara=voramo
      elif [ $varb = t1dava ] ; then
        vara=t1damo
      elif [ $varb = rayava ] ; then
        vara=rayamo
      elif [ $varb = lagava ] ; then
        vara=lagamo
      elif [ $varb = lasava ] ; then
        vara=lasamo
      else
        vara=$varb
      fi
      ln -s $var $vara
    fi
  done
  #
  if [ "$THERMOCHEMISTRY_DATA" != "" ] ; then
    var=$DATA/$THERMOCHEMISTRY_DATA
    if [ -f $var ] ; then
      cp $var dp_tch
      # Copy so as to have correct name upon backup
      if [ "$THERMOCHEMISTRY_DATA" != "dp_tch" ] ; then
        cp dp_tch $THERMOCHEMISTRY_DATA
      fi
    else
      echo ' '
      echo ' -- ERROR -- '
      echo ' The thermochemistry file ' $var
      echo ' can not be accessed. '
      exit 1
    fi
  fi
  #
  if [ "$METEO_DATA" != "" ] ; then
    var=$DATA/$METEO_DATA
    if [ -f $var ] ; then
      cp $var meteo
      # Copy so as to have correct name upon backup
      if [ "$METEO_DATA" != "meteo" ] ; then
        cp meteo $METEO_DATA
      fi
    else
      echo ' '
      echo ' -- ERROR -- '
      echo ' The meteo profile file ' $var
      echo ' can not be accessed. '
      exit 1
    fi
  fi
  #
  for f in uscpcl.f90 usd3pc.f90 usebuc.f90 uslwcc.f90 usfucl.f90
  do
    if [ -f "${SRC}/${f}" -a ! -f JANAF ] ; then
      cp ${datadir}/data/thch/JANAF JANAF
    fi
  done
  #
  if [ ! -z "$USER_INPUT_FILES" ] ; then
    for f in $USER_INPUT_FILES ; do
      cp $DATA/$f .
    done
  fi
  #
fi # EXEC_KERNEL = yes

if [ $I -eq 1 ]; then
########################################################################
# Maximum time for PBS (done here so as to leave time for PBS to
# realize that things have started).
#
if [ "$PBS_JOBID" != "" ] ; then
  CS_MAXTIME=`qstat -r $PBS_JOBID | grep $PBS_JOBID | sed -e's/ \{1,\}/ /g' | cut -d ' ' -f 9`
  export CS_MAXTIME
fi
#
########################################################################
#
# Summary: start
#
CURDATE=`unset LANG ; date`
#
echo '========================================================'>>$summary
echo '   Start time       : ' $CURDATE                         >>$summary
echo '  ----------------------------------------------------'  >>$summary
echo '    Kernel          : ' $prefix                          >>$summary
echo '    Preprocessor    : ' $ecs_prefix                      >>$summary
echo '    ------------------------------------------------  '  >>$summary
echo '    HOMARD          : ' $homard_prefix                   >>$summary
echo '    ------------------------------------------------  '  >>$summary
echo '    CS_MPI_PATH     : ' $CS_MPI_PATH                     >>$summary
echo '    PATH            : ' $PATH                            >>$summary
echo '    ------------------------------------------------  '  >>$summary
echo '    User            : ' $USER                            >>$summary
echo '========================================================'>>$summary
echo '    Machine         : '                                  >>$summary
     uname -a                                                  >>$summary
if [ -z "$NUMBER_OF_PROCESSORS" ] ; then
  echo '    N Procs         : ' 1                              >>$summary
else
  echo '    N Procs         : ' $NUMBER_OF_PROCESSORS          >>$summary
fi
if [ -z "$PROCESSOR_LIST" ] ; then
  echo '    Processors      : ' default                        >>$summary
else
  echo '    Processors      : ' $PROCESSOR_LIST                >>$summary
fi
echo '========================================================'>>$summary
echo '  ----------------------------------------------------'  >>$summary
echo '    Case            : ' $CASE                            >>$summary
echo '      DATA          : ' $DATA                            >>$summary
echo '      SRC           : ' $SRC                             >>$summary
echo '      RESU          : ' $RESU                            >>$summary
echo '  ----------------------------------------------------'  >>$summary
echo '    Exec. dir.      : ' $RUN                             >>$summary
echo '  ----------------------------------------------------'  >>$summary
if [ "$EXEC_PREPROCESSOR" = "yes" ] ; then
  echo '    Preprocessor    : ' ${ecs_bindir}/cs_preprocess    >>$summary
fi
if [ "$EXEC_PARTITION" = "yes" ] ; then
  echo '    Partitioner     : ' ${ecs_bindir}/cs_partition     >>$summary
fi
if [ "$EXEC_KERNEL" = "yes" ] ; then
  echo '    Executable      : ' $EXE                           >>$summary
fi
echo '  ----------------------------------------------------'  >>$summary
#
# Execution
echo
echo  "  ********************************************"
echo  "             Starting calculation"
echo  "  ********************************************"
echo
fi
#
# Preprocessor start
#
if [ "${EXEC_PREPROCESS}" = "yes" ] ; then
  #
  ${ecs_bindir}/cs_preprocess --mesh $MESH "--case" $CASE \
                   $COMMAND_REORIENT $COMMAND_JOIN $COMMAND_PERIO \
                   > listpre 2>&1
  if [ $? != 0 ] ; then
    echo "Error running the preprocessor."
    echo "Check preprocessor log (listpre) for details."
    echo
    PREPROCESS_ERROR=true
    ERROR=true
  fi
  #
  if [ "${EXEC_KERNEL}" = "no" ] ; then
    #
    PREPROCESSOR_OUTPUT_OUT=$RESU/preprocessor_output.$SUFFIX
    cp preprocessor_output ${PREPROCESSOR_OUTPUT_OUT}
  fi
  #
fi
#
# Partitioner start
#
if [ ! -f ${ecs_bindir}/cs_partition ] ; then
  echo "Warning: ${ecs_bindir}/cs_partition not found."
  echo
  echo "The partitioner may not have been installed"
  echo "  (this is the case if neither METIS nor."
  echo "  SCOTCH are avaialable)."
  echo
  echo "Unoptimized partitioning will be used, so"
  echo "parallel performance may be degraded."
  echo
  EXEC_PARTITION=no
fi
#
if [ "${EXEC_PARTITION}" = "yes" ] ; then
  #
  if [ "${EXEC_KERNEL}" = "yes" ] ; then
    ${ecs_bindir}/cs_partition $nproc_kernel > listpart 2>&1
  else
    if [ -z "$PARTITION_LIST" ] ; then
      echo "Error running the partitioner."
      echo "PARTITION_LIST is not set."
      echo "This variable should contain the number of processors"
      echo "for which we partition (or a list of such numbers)."
      PARTITION_ERROR=true
      ERROR=true
    else
      ${ecs_bindir}/cs_partition $PARTITION_LIST > listpart 2>&1
    fi
  fi
  if [ $? != 0 -a $PARTITION_ERROR = false ] ; then
    echo "Error running the partitioner."
    echo "Check partitioner log (listpart) for details."
    echo
    PARTITION_ERROR=true
    ERROR=true
  fi
  #
  if [ "${EXEC_KERNEL}" = "no" ] ; then
    #
    PARTITION_OUTPUT_OUT=$RESU/PARTITION_OUTPUT.$SUFFIX
    mkdir $PARTITION_OUTPUT_OUT
    cp -r domain_number_* ${PARTITION_OUTPUT_OUT}/
  fi
#
fi
done
#
# Run calculation proper.
#
if [ "$ERROR" != "true" -a "$EXEC_KERNEL" = "yes" ] ; then
#
NB_TOT=0
I=0
while [ $I -lt $NB_INSTANCES ]; do
    (( I=I+1 ))
    cur_dir=$RUN/RUN.$I

    COMMAND_CWF=`eval echo '$COMMANDE_CWF_'$I`
    NUMBER_OF_PROCESSORS=`eval echo '$NUMBER_OF_PROCESSORS_'$I`
    (( NB_TOT=NB_TOT+$NUMBER_OF_PROCESSORS ))
    #
    cd $RUN

    RUNCS="$VALGRIND $cur_dir/$EXE --mpi $I \
           $COMMAND_CWF $ARG_CS_VERIF $ARG_CS_OUTPUT $COMMAND_PARAM"
    CMD="cd $cur_dir && $RUNCS"

    # MPI Communication
    #
    # Make sure to transmit possible additional arguments assigned by mpirun to
    # the executable with some MPI-1 implementations (vanilla MPICH 1.2 sets the
    # parameters needed by MPI_Init through argc/argv): we use $@ to forward
    # arguments passed to localexec to the true executable files.
    #
    localexec=$RUN/localexec
    if [ $I -eq 1 ]; then
    echo '#!/bin/sh' > $localexec
    echo "MPI_RANK=\`${pkgdatadir}/runcase_mpi_rank \$@\`" >> $localexec
    echo "if [ \$MPI_RANK -lt $NB_TOT ] ; then" >> $localexec
    echo "  $CMD" >> $localexec
    elif [ $I -lt $NB_INSTANCES ]; then
    echo "elif [ \$MPI_RANK -lt $NB_TOT ] ; then" >> $localexec
    echo "  $CMD" >> $localexec
    else
    echo "else" >> $localexec
    echo "  $CMD" >> $localexec
    echo "fi" >> $localexec
    fi
    chmod 700 $localexec

done

$MPIBOOT
$MPIRUN $localexec || EXECUTION_ERROR=true
$MPIHALT

fi
#
########################################################################
#
# Treatment of the ouput files:
#   Starts with the restart files
#   (in case of full disk, increases chances of being able to continue).
#
I=0
while [ $I -lt $NB_INSTANCES ]; do
 (( I=I+1 ))
#
  SUFFIX=$I.$DATE
#
  cur_dir=$RUN/RUN.$I
  cd $cur_dir

  USER_OUTPUT_FILES=`eval echo '$USER_OUTPUT_FILES_'$I`

if [ $EXEC_KERNEL = yes ] ; then

  RESTART_OUT=$RESU/RESTART.$SUFFIX
  iok=1
  mkdir ${RESTART_OUT} || iok=0
  if [ $iok = 1 ] ; then
    for f in suiava suiavx t1dava vorava rayava lagava* lasava* ; do
      if [ -f $f ] ; then
        cp $f ${RESTART_OUT}
      fi
    done
  else
    for f in suiava suiavx t1dava vorava rayava lagava* lasava* ; do
      if [ -f $f ] ; then
        cp $f $RESU/$f.$SUFFIX
      fi
    done
  fi

  resuser=0
  for f in ${USER_OUTPUT_FILES} ; do
    if [ -f $f ] ; then
      resuser=1
    fi
  done
  if [ ${resuser} = 1 ] ; then
    RES_USER=$RESU/RES_USER.$SUFFIX
    iok=1
    mkdir ${RES_USER} || iok=0
    if [ $iok = 1 ] ; then
      for f in ${USER_OUTPUT_FILES} ; do
        if [ -f $f ] ; then
          cp $f ${RES_USER}
        fi
      done
    else
      for f in ${USER_OUTPUT_FILES} ; do
        if [ -f $f ] ; then
          cp $f $RESU/$f.$SUFFIX
        fi
      done
    fi
  fi

  for f in $PARAM $THERMOCHEMISTRY_DATA $METEO_DATA ; do
    if [ -f $f ] ; then
      cp $f $RESU/$f.$SUFFIX
    fi
  done

  for f in *.hst ; do
    if [ -f $f ] ; then
      if [ ! -d $RESU/HIST.$SUFFIX ] ; then
        mkdir $RESU/HIST.$SUFFIX
      fi
      cp $f $RESU/HIST.$SUFFIX
    fi
  done
  for f in ush* ; do
    if [ -f $f ] ; then
      if [ ! -d $RESU/HIST.$SUFFIX ] ; then
        mkdir $RESU/HIST.$SUFFIX
      fi
      cp $f $RESU/HIST.$SUFFIX
    fi
  done

fi  # output files

for f in list* error* *.med *.cgns ; do
  if [ -f $f ] ; then
    cp $f $RESU/$f.$SUFFIX
  fi
done

# Treatment of EnSight and MED files
#   The $dir (=*.ensight and/or *.med) directories are copied
#   to $DIR.$SUFFIX

#   We place directories $dir (=*.ensight and/or *.med)
#   in $DIR.$SUFFIX

cas=`echo $CASE |tr "[:upper:]" "[:lower:]"`

for dir in *.ensight *.med ; do
  if [ -d $dir ] ; then
    DIR=`echo $dir |tr "[:lower:]" "[:upper:]"`
    mkdir $RESU/$DIR.$SUFFIX
    if [ $? -ne 0 ] ; then
      echo Creating $RESU/$DIR.$SUFFIX failed
    else
      for f in $dir/*  ; do
        if [ -f $f ] ; then
          cp -R ${f} $RESU/$DIR.$SUFFIX/.
        fi
      done
    fi
  fi
done

if [ $EXEC_KERNEL = yes ] ; then

  rayt_list=`ls bord* 2>/dev/null`
  if [ ! -z "${rayt_list}" ] ; then
    for f in $rayt_list ; do
      if [ ! -d $RESU/CHR.$SUFFIX ] ; then
        mkdir $RESU/CHR.$SUFFIX
      fi
      cp $f $RESU/CHR.$SUFFIX/.
    done
  fi

  lagr_list=`ls debug* deplacement* trajectoire* frontiere* 2>/dev/null`
  if [ ! -z "${lagr_list}" ] ; then
    mkdir $RESU/LAGR.$SUFFIX
    for f in $lagr_list ; do
      cp $f $RESU/LAGR.$SUFFIX
    done
  fi

  # Matisse output files
  if [ -f ${RUN}/resuMatisse ] ; then
    matisse=`grep -i matisse $DATA/$PARAM`
    if [ ! -z "$matisse" ] ; then
  # The date is added to the first line of resuMatisse
      AFDATE="Date of the case                                       : "$DATE
      sed  "1i\ ${AFDATE}" ${RUN}/resuMatisse >> ${RUN}/resuMatisse.mod
      mv ${RUN}/resuMatisse.mod ${RUN}/resuMatisse
    fi
    cp ${RUN}/resuMatisse ${RESU}/resuMatisse.$SUFFIX
  fi

  for dir in src_saturne ; do
    if [ -d $dir ] ; then
      mkdir $RESU/SRC.$SUFFIX
      if [ $? -ne 0 ] ; then
        echo Failure creating $RESU/SRC.$SUFFIX
      else
        for f in $dir/*.[fF]90 $dir/*.[ch] ; do
          if [ -f ${f} ] ; then
            cp -R ${f} $RESU/SRC.$SUFFIX/.
            fbase=`basename ${f}`
            chmod a-w $RESU/SRC.$SUFFIX/${fbase}
          fi
        done
      fi
    fi
  done

fi  # input data and outputs
done
#
########################################################################
#
# Summary: end
#
if  [ "$PREPROCESS_ERROR" = "true" ] ; then
  EXEC_PREPROCESS="failed"
fi
echo "    Preprocessing   : " $EXEC_PREPROCESS                 >>$summary
if  [ "$PARTITION_ERROR" = "true" ] ; then
  EXEC_PARTITION="failed"
fi
echo "    Partitioning    : " $EXEC_PARTITION                  >>$summary
if  [ "$EXECUTION_ERROR" = "true" ] ; then
  EXEC_KERNEL="failed"
fi
echo "    Calculation     : " $EXEC_KERNEL                     >>$summary
#
CURDATE=`unset LANG ; date`
#
echo '  ----------------------------------------------------'  >>$summary
echo '   Finish time      : ' $CURDATE                         >>$summary
echo '========================================================'>>$summary
#
cp $summary  $RESU/$summary.$SUFFIX
#
########################################################################
#
#
# Finish
#
echo
echo  "  ********************************************"
if [ "$EXECUTION_ERROR" = "true" ] ; then
  echo  "         Error in calculation stage."
elif  [ "$PARTITION_ERROR" = "true" ] ; then
  echo  "         Error in partitioning stage."
elif  [ "$PREPROCESS_ERROR" = "true" ] ; then
  echo  "         Error in preprocessing stage."
else
  echo  "           Normal simulation finish"
fi
echo  "  ********************************************"

if [ "$ERROR" = "true" ] ; then
  exit 1
else
  exit 0
fi
#
########################################################################
